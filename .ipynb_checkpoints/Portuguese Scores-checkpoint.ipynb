{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portuguese Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\mhous\\\\Test Scores')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "train_por = pd.read_csv('train_por.csv')\n",
    "test_por = pd.read_csv('test_por.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "We begin with regression on the Portuguese G3 scores, which range from 1-20. We create a baseline model, which is the mean G3 score in training data. We can then compare the RMSE of this model to the random forest models. We then train a baseline random forest model, and then use RandomizedSearchCV to tune the hyperparameters. Finally we evaluate the best estimator found in the RandomizedSearchCV and analyze the feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of baseline model: 2.681\n"
     ]
    }
   ],
   "source": [
    "baseline = train_por['G3'].mean()\n",
    "baseline_array = np.full(len(test_por), baseline)\n",
    "rmse = np.sqrt(mean_squared_error(test_por['G3'], baseline_array))\n",
    "print(\"RMSE of baseline model: %.3f\" %rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_por.drop(['G1', 'G2', 'G3', 'G3_five_levels', 'G3_pass_fail'], axis=1)\n",
    "y_train = train_por['G3']\n",
    "\n",
    "X_test = test_por.drop(['G1', 'G2', 'G3', 'G3_five_levels', 'G3_pass_fail'], axis=1)\n",
    "y_test = test_por['G3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    print(\"RMSE: % .3f\" %rmse)\n",
    "    print(\"R-Squared: % .3f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state=1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  2.406\n",
      "R-Squared:  0.185\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(100,  2000, 20)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2,5,10]\n",
    "min_samples_leaf = [1,2,4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  7.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(random_state=1),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         900, 1000, 1100, 1200,\n",
       "                                                         1300, 1400, 1500, 1600,\n",
       "                                                         1700, 1800, 1900,\n",
       "                                                         2000]},\n",
       "                   random_state=1, verbose=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random = RandomizedSearchCV(RandomForestRegressor(random_state=1), param_distributions = random_grid, n_iter = 50, cv = 5, verbose=1, random_state=1, n_jobs=-1)\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1900, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 90, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "print(rf_random.best_params_)\n",
    "rf_best = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  2.315\n",
      "R-Squared:  0.246\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(rf_best, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best estimator from the RandomizedSearchCV was able to reduce the RMSE by about .1 from our initial random forest model. This is also an improvement of .35 from our baseline model. The R-squared difference from the first random forest to the the best estimator is .061, which shows a decent increase in explanatory power. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_importances(model):\n",
    "    importances = model.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in model.estimators_],\n",
    "             axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    print(\"Feature ranking:\")\n",
    "    for f in range(10):\n",
    "        print(\"%d. Feature: %s (%f)\" % (f + 1, X_train.columns[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. Feature: failures (0.123063)\n",
      "2. Feature: higher (0.058370)\n",
      "3. Feature: absences (0.048330)\n",
      "4. Feature: Medu (0.046176)\n",
      "5. Feature: age (0.043466)\n",
      "6. Feature: goout (0.043195)\n",
      "7. Feature: Dalc (0.042807)\n",
      "8. Feature: Walc (0.041092)\n",
      "9. Feature: freetime (0.038160)\n",
      "10. Feature: school (0.038014)\n"
     ]
    }
   ],
   "source": [
    "variable_importances(rf_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that number of failures and the desire to attend higher education are the most important predictors, followed by other logical variables such as number of absences and mother's education. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we move onto a five level classification task. The five levels classification is as follows:\n",
    "\n",
    "| Level      | G3 Score |\n",
    "| :----------- | -----------|\n",
    "| 1      |    16-20   |\n",
    "| 2   |    14-15     |\n",
    "| 3   |   12-13     |\n",
    "| 4   |   10-11      |\n",
    "| 5   | 0-9 |\n",
    "\n",
    "In this case, our baseline model is the most common class in the training data. \n",
    "\n",
    "We again begin with creating a base model, then using RandomizedSearchCV to tune the hyperparameters, then evaluating the model using the classification report and confusion matrix. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of baseline model: 0.314\n"
     ]
    }
   ],
   "source": [
    "most_common_class = train_por['G3_five_levels'].value_counts().sort_values(ascending=False).index[0]\n",
    "classified_correctly = 0\n",
    "for i in range(len(train_por)):\n",
    "    if train_por['G3_five_levels'][i] == most_common_class:\n",
    "        classified_correctly +=1 \n",
    "print(\"Mean accuracy of baseline model: \" + str(round(classified_correctly/len(train_por), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_por.drop(['G1', 'G2', 'G3', 'G3_five_levels', 'G3_pass_fail'], axis=1)\n",
    "y_train = train_por['G3_five_levels']\n",
    "\n",
    "X_test = test_por.drop(['G1', 'G2', 'G3', 'G3_five_levels', 'G3_pass_fail'], axis=1)\n",
    "y_test = test_por['G3_five_levels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.346\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=1)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_base_score = round(rf.score(X_test, y_test), 3)\n",
    "print(\"Mean accuracy: \" + str(rf_base_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=1),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         900, 1000, 1100, 1200,\n",
       "                                                         1300, 1400, 1500, 1600,\n",
       "                                                         1700, 1800, 1900,\n",
       "                                                         2000]},\n",
       "                   random_state=1, verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random = RandomizedSearchCV(RandomForestClassifier(random_state=1), param_distributions = random_grid, n_iter = 50, cv = 5, verbose=1, random_state=1, n_jobs=-1)\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': None, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "print(rf_random.best_params_)\n",
    "rf_best = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.3231\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy: \" + str(round(rf_best.score(X_test, y_test), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our RandomizedSearchCV best estimator is worse than our base random forest, so that's the model we'll use to to analyze our predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.30      0.23      0.26        13\n",
      "           2       0.11      0.08      0.10        24\n",
      "           3       0.44      0.40      0.42        40\n",
      "           4       0.37      0.55      0.44        38\n",
      "           5       0.33      0.20      0.25        15\n",
      "\n",
      "    accuracy                           0.35       130\n",
      "   macro avg       0.31      0.29      0.29       130\n",
      "weighted avg       0.33      0.35      0.33       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  3,  4,  3,  0],\n",
       "       [ 4,  2,  8,  9,  1],\n",
       "       [ 1,  8, 16, 15,  0],\n",
       "       [ 1,  4,  7, 21,  5],\n",
       "       [ 1,  1,  1,  9,  3]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find our model does a good decent job at predicting who will score a 3/4, but poorly everywhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. Feature: failures (0.066995)\n",
      "2. Feature: absences (0.059327)\n",
      "3. Feature: Medu (0.050092)\n",
      "4. Feature: Walc (0.046229)\n",
      "5. Feature: health (0.045712)\n",
      "6. Feature: age (0.041973)\n",
      "7. Feature: freetime (0.040540)\n",
      "8. Feature: Fedu (0.040072)\n",
      "9. Feature: goout (0.038092)\n",
      "10. Feature: higher (0.036883)\n"
     ]
    }
   ],
   "source": [
    "variable_importances(rf_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass/Fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we move onto our pass/fail classification system. Passing counts as scoring a 10 or higher on the G3 grades, and failing is scoring 0-9. Our baseline is again the most common class in the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_por.drop(['G1', 'G2', 'G3', 'G3_five_levels', 'G3_pass_fail'], axis=1)\n",
    "y_train = train_por['G3_pass_fail']\n",
    "\n",
    "X_test = test_por.drop(['G1', 'G2', 'G3', 'G3_five_levels', 'G3_pass_fail'], axis=1)\n",
    "y_test = test_por['G3_pass_fail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of baseline model: 0.836\n"
     ]
    }
   ],
   "source": [
    "most_common_class = train_por['G3_pass_fail'].value_counts().sort_values(ascending=False).index[0]\n",
    "classified_correctly = 0\n",
    "for i in range(len(train_por)):\n",
    "    if train_por['G3_pass_fail'][i] == most_common_class:\n",
    "        classified_correctly +=1 \n",
    "print(\"Mean accuracy of baseline model: \" + str(round(classified_correctly/len(train_por), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.854\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_base_score = round(rf.score(X_test, y_test), 3)\n",
    "print(\"Mean accuracy: \" + str(rf_base_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        15\n",
      "           1       0.88      0.97      0.92       115\n",
      "\n",
      "    accuracy                           0.85       130\n",
      "   macro avg       0.44      0.48      0.46       130\n",
      "weighted avg       0.78      0.85      0.81       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   26.3s\n"
     ]
    }
   ],
   "source": [
    "rf_random = RandomizedSearchCV(RandomForestClassifier(random_state=1), param_distributions = random_grid, n_iter = 50, cv = 5, verbose=1, random_state=1, n_jobs=-1)\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_random.best_params_)\n",
    "rf_best = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean accuracy: \" + str(round(rf_best.score(X_test, y_test), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our RandomizedSearchCV is less accurate than the initial random forest model, so we use that model to analyze our predictions. The model is really well at predicting who will pass, and does poorly at predicting who will fail. The model predicted 111/115 passing scores, but predicted 4 people to fail who actually passed. The model also predicted that 15 people would pass who actually ended up failing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_importances(rf_best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
