{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Math Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir('C:\\\\Users\\\\mhous\\\\Test Scores')\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, confusion_matrix, classification_report, plot_confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "\n",
    "train_mat = pd.read_csv('train_mat.csv')\n",
    "test_mat = pd.read_csv('test_mat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "We begin with regression on the G3 scores, which range from 1-20. We create a baseline model, which is the mean G3 score in training data. We can then compare the RMSE of this model to the random forest models. We then train a baseline random forest model, and then use RandomizedSearchCV to tune the hyperparameters. Finally we evaluate the best estimator found in the RandomizedSearchCV and analyze the feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of baseline model: 4.912\n"
     ]
    }
   ],
   "source": [
    "baseline = train_mat['G3'].mean()\n",
    "baseline_array = np.full(len(test_mat), baseline)\n",
    "rmse = np.sqrt(mean_squared_error(test_mat['G3'], baseline_array))\n",
    "print(\"RMSE of baseline model: %.3f\" %rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_mat.drop(['G1', 'G2', 'G3', 'G3_five_levels', 'G3_pass_fail'], axis=1)\n",
    "y_train = train_mat['G3']\n",
    "\n",
    "X_test = test_mat.drop(['G1', 'G2', 'G3', 'G3_five_levels', 'G3_pass_fail'], axis=1)\n",
    "y_test = test_mat['G3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_regression_model(model, X_test, y_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "    print(\"RMSE: % .3f\" %rmse)\n",
    "    print(\"R-Squared: % .3f\"%r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  3.899\n",
      "R-Squared:  0.370\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state=1)\n",
    "rf.fit(X_train, y_train)\n",
    "evaluate_regression_model(rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(100,  2000, 20)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2,5,10]\n",
    "min_samples_leaf = [1,2,4]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestRegressor(random_state=1),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         900, 1000, 1100, 1200,\n",
       "                                                         1300, 1400, 1500, 1600,\n",
       "                                                         1700, 1800, 1900,\n",
       "                                                         2000]},\n",
       "                   random_state=1, verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random = RandomizedSearchCV(RandomForestRegressor(random_state=1), param_distributions = random_grid, n_iter = 50, cv = 5, verbose=1, random_state=1, n_jobs=-1)\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'auto', 'max_depth': None, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "print(rf_random.best_params_)\n",
    "rf_best = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  3.886\n",
      "R-Squared:  0.374\n"
     ]
    }
   ],
   "source": [
    "evaluate_regression_model(rf_best, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RandomizedSearch improved our model very slightly, with an 0.013 decrease in RMSE and a .004 improvement in R-Squared. Let's now look at the most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variable_importances(model):\n",
    "    importances = model.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in model.estimators_],\n",
    "             axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    print(\"Feature ranking:\")\n",
    "    for f in range(10):\n",
    "        print(\"%d. Feature: %s (%f)\" % (f + 1, X_train.columns[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. Feature: absences (0.221063)\n",
      "2. Feature: failures (0.155510)\n",
      "3. Feature: goout (0.041093)\n",
      "4. Feature: health (0.037930)\n",
      "5. Feature: studytime (0.035995)\n",
      "6. Feature: freetime (0.035763)\n",
      "7. Feature: Medu (0.033888)\n",
      "8. Feature: traveltime (0.033178)\n",
      "9. Feature: age (0.031372)\n",
      "10. Feature: schoolsup (0.025548)\n"
     ]
    }
   ],
   "source": [
    "variable_importances(rf_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one might expect, the number of absences and the number of failures are the most important variables when it comes to the regression model. There is a sharp drop off in importance with the rest of the features that account for 4% or less. \n",
    "\n",
    "Overall, our random forest regression model is an improvement over the baseline model, but since the RMSE being ~3.9 means we aren't very accurate when it comes to predicting final test scores. This might be due to an insufficient amount of data, missing important features such as income, or just the irreducible error in predicting final test scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Five Levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we move onto a five level classification task. The five levels classification is as follows:\n",
    "\n",
    "| Level      | G3 Score |\n",
    "| :----------- | -----------|\n",
    "| 1      |    16-20   |\n",
    "| 2   |    14-15     |\n",
    "| 3   |   12-13     |\n",
    "| 4   |   10-11      |\n",
    "| 5   | 0-9 |\n",
    "\n",
    "In this case, our baseline model is the most common class in the training data. \n",
    "\n",
    "We again begin with creating a base model, then using RandomizedSearchCV to tune the hyperparameters, then evaluating the model using the classification report and confusion matrix. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_mat.drop(['G1', 'G2', 'G3', 'G3_five_levels', 'G3_pass_fail'], axis=1)\n",
    "y_train = train_mat['G3_five_levels']\n",
    "\n",
    "X_test = test_mat.drop(['G1', 'G2', 'G3', 'G3_five_levels', 'G3_pass_fail'], axis=1)\n",
    "y_test = test_mat['G3_five_levels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of baseline model: 0.35\n"
     ]
    }
   ],
   "source": [
    "most_common_class = train_mat['G3_five_levels'].value_counts().sort_values(ascending=False).index[0]\n",
    "classified_correctly = 0\n",
    "for i in range(len(test_mat)):\n",
    "    if test_mat['G3_five_levels'][i] == most_common_class:\n",
    "        classified_correctly +=1 \n",
    "print(\"Mean accuracy of baseline model: \" + str(round(classified_correctly/len(test_mat), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_model(model, X_test, y_test):\n",
    "    model_base_score = rf.score(X_test, y_test)\n",
    "    print(\"Mean accuracy: % .3f\" % model_base_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy:  0.317\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=1)\n",
    "rf.fit(X_train, y_train)\n",
    "evaluate_classification_model(rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=1),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         900, 1000, 1100, 1200,\n",
       "                                                         1300, 1400, 1500, 1600,\n",
       "                                                         1700, 1800, 1900,\n",
       "                                                         2000]},\n",
       "                   random_state=1, verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random = RandomizedSearchCV(RandomForestClassifier(random_state=1), param_distributions = random_grid, n_iter = 50, cv = 5, verbose=1, random_state=1, n_jobs=-1)\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 70, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "print(rf_random.best_params_)\n",
    "rf_best = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.35\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy: \" + str(round(rf_best.score(X_test, y_test), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.33      0.14      0.20         7\n",
      "           2       0.12      0.10      0.11        10\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.26      0.36      0.30        14\n",
      "           5       0.52      0.67      0.58        21\n",
      "\n",
      "    accuracy                           0.35        60\n",
      "   macro avg       0.25      0.25      0.24        60\n",
      "weighted avg       0.30      0.35      0.32        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = rf_best.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  2,  0,  3,  1],\n",
       "       [ 1,  1,  1,  4,  3],\n",
       "       [ 0,  1,  0,  4,  3],\n",
       "       [ 1,  2,  0,  5,  6],\n",
       "       [ 0,  2,  2,  3, 14]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that our five level classification has a mean accuracy of .35 and that it is much better at predicting who will do worse than who will do well. For example, the model predicted that 3 people would score a 1, the highest possible level, but only one of those predictions was true (precision = .33). Additionally, there were 7 people who scored a 1, and only 1 of those 7 was correctly predicted (recall = .14). The model performs better at predicting who is likely to fail, where the precision and recall values are .52 and .67, respectively. \n",
    "\n",
    "Ultimately though, our five level classification model was equally accurate as just predicting every student will score a 5, so the model really does not do a good job of predicting how students score on the five level scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. Feature: absences (0.084653)\n",
      "2. Feature: failures (0.070682)\n",
      "3. Feature: Medu (0.048718)\n",
      "4. Feature: goout (0.046857)\n",
      "5. Feature: health (0.044957)\n",
      "6. Feature: freetime (0.043805)\n",
      "7. Feature: Walc (0.042381)\n",
      "8. Feature: studytime (0.040545)\n",
      "9. Feature: famrel (0.036357)\n",
      "10. Feature: age (0.035003)\n"
     ]
    }
   ],
   "source": [
    "variable_importances(rf_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable importances in this model are much more evenly distributed. Absences again is the most predictive variable, but interestingly failures in now the 6th most important variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pass/Fail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we move onto our pass/fail classification system. Passing counts as scoring a 10 or higher on the G3 grades, and failing is scoring 0-9. Our baseline is again the most common class in the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy of baseline model: 0.65\n"
     ]
    }
   ],
   "source": [
    "most_common_class = train_mat['G3_pass_fail'].value_counts().sort_values(ascending=False).index[0]\n",
    "classified_correctly = 0\n",
    "for i in range(len(test_mat)):\n",
    "    if test_mat['G3_pass_fail'][i] == most_common_class:\n",
    "        classified_correctly +=1 \n",
    "print(\"Mean accuracy of baseline model: \" + str(round(classified_correctly/len(test_mat), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_mat.drop(['G1', 'G2', 'G3', 'G3_five_levels', 'G3_pass_fail'], axis=1)\n",
    "y_train = train_mat['G3_pass_fail']\n",
    "\n",
    "X_test = test_mat.drop(['G1', 'G2', 'G3', 'G3_five_levels', 'G3_pass_fail'], axis=1)\n",
    "y_test = test_mat['G3_pass_fail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.717\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=1)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_base_score = round(rf.score(X_test, y_test), 3)\n",
    "print(\"Mean accuracy: \" + str(rf_base_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   49.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  4.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=1),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500, 600, 700, 800,\n",
       "                                                         900, 1000, 1100, 1200,\n",
       "                                                         1300, 1400, 1500, 1600,\n",
       "                                                         1700, 1800, 1900,\n",
       "                                                         2000]},\n",
       "                   random_state=1, verbose=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random = RandomizedSearchCV(RandomForestClassifier(random_state=1), param_distributions = random_grid, n_iter = 50, cv = 5, verbose=1, random_state=1, n_jobs=-1)\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': None, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "print(rf_random.best_params_)\n",
    "rf_best = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.7\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean accuracy: \" + str(round(rf_best.score(X_test, y_test), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.29      0.40        21\n",
      "           1       0.71      0.92      0.80        39\n",
      "\n",
      "    accuracy                           0.70        60\n",
      "   macro avg       0.69      0.60      0.60        60\n",
      "weighted avg       0.69      0.70      0.66        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = rf_best.predict(X_test)\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6, 15],\n",
       "       [ 3, 36]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, this model is better at predicting who will pass than who will fail. The model correctly predicted 36/39 students that actually passed, but also predicted that 15 students would pass that actually failed. This goes in hand with the low recall in predicting who would fail, correctly predictingg only 6/21. \n",
    "\n",
    "Our pass/fail random forest model performs better than our baseline model does by 5%, which shows the model does a better job at predicting  who will pass/fail than by random chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. Feature: failures (0.152744)\n",
      "2. Feature: absences (0.104087)\n",
      "3. Feature: goout (0.068500)\n",
      "4. Feature: age (0.046360)\n",
      "5. Feature: Medu (0.041301)\n",
      "6. Feature: Walc (0.036933)\n",
      "7. Feature: Fedu (0.036532)\n",
      "8. Feature: health (0.034572)\n",
      "9. Feature: freetime (0.030661)\n",
      "10. Feature: famrel (0.029877)\n"
     ]
    }
   ],
   "source": [
    "variable_importances(rf_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, in the top 10 most important features we see a lot of similarities as before. Failures makes its way to the most important feature, and absences is again one of the most explanatory features>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
